Training...


**************************************************************************************************** 
FOLD: 1
Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b1_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
27164672/27164032 [==============================] - 0s 0us/step

Model initialized and compiled: EfficientNet-B1

Model training...

Epoch 1/25
176/176 - 272s - loss: 0.3545 - auc: 0.8708 - val_loss: 0.3261 - val_auc: 0.9089

Epoch 00001: val_auc improved from -inf to 0.90890, saving model to /kaggle/working/models/model-f1.h5
Epoch 2/25
176/176 - 165s - loss: 0.2960 - auc: 0.9314 - val_loss: 0.3043 - val_auc: 0.9307

Epoch 00002: val_auc improved from 0.90890 to 0.93072, saving model to /kaggle/working/models/model-f1.h5
Epoch 3/25
176/176 - 162s - loss: 0.2846 - auc: 0.9410 - val_loss: 0.2903 - val_auc: 0.9425

Epoch 00003: val_auc improved from 0.93072 to 0.94253, saving model to /kaggle/working/models/model-f1.h5
Epoch 4/25
176/176 - 159s - loss: 0.2773 - auc: 0.9468 - val_loss: 0.2821 - val_auc: 0.9474

Epoch 00004: val_auc improved from 0.94253 to 0.94739, saving model to /kaggle/working/models/model-f1.h5
Epoch 5/25
176/176 - 160s - loss: 0.2702 - auc: 0.9518 - val_loss: 0.2788 - val_auc: 0.9488

Epoch 00005: val_auc improved from 0.94739 to 0.94876, saving model to /kaggle/working/models/model-f1.h5
Epoch 6/25
176/176 - 160s - loss: 0.2645 - auc: 0.9555 - val_loss: 0.2755 - val_auc: 0.9511

Epoch 00006: val_auc improved from 0.94876 to 0.95106, saving model to /kaggle/working/models/model-f1.h5
Epoch 7/25
176/176 - 159s - loss: 0.2580 - auc: 0.9594 - val_loss: 0.2778 - val_auc: 0.9495

Epoch 00007: val_auc did not improve from 0.95106
Epoch 8/25
176/176 - 167s - loss: 0.2510 - auc: 0.9634 - val_loss: 0.2755 - val_auc: 0.9497

Epoch 00008: val_auc did not improve from 0.95106
Epoch 9/25
176/176 - 166s - loss: 0.2446 - auc: 0.9668 - val_loss: 0.2806 - val_auc: 0.9467

Epoch 00009: val_auc did not improve from 0.95106
Epoch 10/25
176/176 - 167s - loss: 0.2363 - auc: 0.9713 - val_loss: 0.2757 - val_auc: 0.9502

Epoch 00010: val_auc did not improve from 0.95106
Epoch 11/25
176/176 - 167s - loss: 0.2341 - auc: 0.9722 - val_loss: 0.2762 - val_auc: 0.9499

Epoch 00011: val_auc did not improve from 0.95106
Epoch 12/25
176/176 - 167s - loss: 0.2337 - auc: 0.9724 - val_loss: 0.2771 - val_auc: 0.9495

Epoch 00012: val_auc did not improve from 0.95106
Epoch 13/25
176/176 - 167s - loss: 0.2322 - auc: 0.9731 - val_loss: 0.2767 - val_auc: 0.9497

Epoch 00013: val_auc did not improve from 0.95106
Epoch 14/25
176/176 - 168s - loss: 0.2316 - auc: 0.9735 - val_loss: 0.2769 - val_auc: 0.9496

Epoch 00014: val_auc did not improve from 0.95106
Epoch 15/25
176/176 - 167s - loss: 0.2321 - auc: 0.9733 - val_loss: 0.2769 - val_auc: 0.9495

Epoch 00015: val_auc did not improve from 0.95106
Epoch 16/25
176/176 - 168s - loss: 0.2318 - auc: 0.9733 - val_loss: 0.2768 - val_auc: 0.9496

Epoch 00016: val_auc did not improve from 0.95106
Epoch 00016: early stopping

Model trained 

FOLD-1 Validation AUC = 0.95106440782547