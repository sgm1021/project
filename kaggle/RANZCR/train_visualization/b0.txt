Training...


**************************************************************************************************** 
FOLD: 1
Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
16809984/16804768 [==============================] - 0s 0us/step

Model initialized and compiled: EfficientNet-B0

Model training...

Epoch 1/25
176/176 - 240s - loss: 0.3538 - auc: 0.8737 - val_loss: 0.3408 - val_auc: 0.8975

Epoch 00001: val_auc improved from -inf to 0.89750, saving model to /kaggle/working/models/model-f1.h5
Epoch 2/25
176/176 - 165s - loss: 0.2953 - auc: 0.9319 - val_loss: 0.2994 - val_auc: 0.9338

Epoch 00002: val_auc improved from 0.89750 to 0.93377, saving model to /kaggle/working/models/model-f1.h5
Epoch 3/25
176/176 - 160s - loss: 0.2845 - auc: 0.9410 - val_loss: 0.2922 - val_auc: 0.9401

Epoch 00003: val_auc improved from 0.93377 to 0.94013, saving model to /kaggle/working/models/model-f1.h5
Epoch 4/25
176/176 - 160s - loss: 0.2768 - auc: 0.9472 - val_loss: 0.2853 - val_auc: 0.9440

Epoch 00004: val_auc improved from 0.94013 to 0.94400, saving model to /kaggle/working/models/model-f1.h5
Epoch 5/25
176/176 - 161s - loss: 0.2709 - auc: 0.9514 - val_loss: 0.2812 - val_auc: 0.9465

Epoch 00005: val_auc improved from 0.94400 to 0.94651, saving model to /kaggle/working/models/model-f1.h5
Epoch 6/25
176/176 - 160s - loss: 0.2643 - auc: 0.9558 - val_loss: 0.2775 - val_auc: 0.9489

Epoch 00006: val_auc improved from 0.94651 to 0.94889, saving model to /kaggle/working/models/model-f1.h5
Epoch 7/25
176/176 - 160s - loss: 0.2586 - auc: 0.9590 - val_loss: 0.2802 - val_auc: 0.9473

Epoch 00007: val_auc did not improve from 0.94889
Epoch 8/25
176/176 - 166s - loss: 0.2529 - auc: 0.9624 - val_loss: 0.2839 - val_auc: 0.9452

Epoch 00008: val_auc did not improve from 0.94889
Epoch 9/25
176/176 - 166s - loss: 0.2461 - auc: 0.9660 - val_loss: 0.2816 - val_auc: 0.9475

Epoch 00009: val_auc did not improve from 0.94889
Epoch 10/25
176/176 - 166s - loss: 0.2395 - auc: 0.9695 - val_loss: 0.2781 - val_auc: 0.9487

Epoch 00010: val_auc did not improve from 0.94889
Epoch 11/25
176/176 - 166s - loss: 0.2371 - auc: 0.9708 - val_loss: 0.2786 - val_auc: 0.9488

Epoch 00011: val_auc did not improve from 0.94889
Epoch 12/25
176/176 - 166s - loss: 0.2364 - auc: 0.9712 - val_loss: 0.2789 - val_auc: 0.9486

Epoch 00012: val_auc did not improve from 0.94889
Epoch 13/25
176/176 - 166s - loss: 0.2355 - auc: 0.9714 - val_loss: 0.2788 - val_auc: 0.9487

Epoch 00013: val_auc did not improve from 0.94889
Epoch 14/25
176/176 - 165s - loss: 0.2353 - auc: 0.9718 - val_loss: 0.2788 - val_auc: 0.9487

Epoch 00014: val_auc did not improve from 0.94889
Epoch 15/25
176/176 - 166s - loss: 0.2347 - auc: 0.9719 - val_loss: 0.2788 - val_auc: 0.9487

Epoch 00015: val_auc did not improve from 0.94889
Epoch 16/25
176/176 - 166s - loss: 0.2351 - auc: 0.9717 - val_loss: 0.2788 - val_auc: 0.9487

Epoch 00016: val_auc did not improve from 0.94889
Epoch 00016: early stopping

Model trained 

FOLD-1 Validation AUC = 0.9488896131515503